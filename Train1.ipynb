{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b021cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import patient as p\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import myLib\n",
    "import consts as c\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ced8101d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mLoading data of patient MSEL_00172\u001b[37m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 248/248 [00:12<00:00, 20.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mLoading data of patient MSEL_00501\u001b[37m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 277/277 [00:13<00:00, 19.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mLoading data of patient MSEL_01097\u001b[37m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 416/416 [00:21<00:00, 19.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mLoading data of patient MSEL_01575\u001b[37m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 438/438 [00:19<00:00, 22.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mLoading data of patient MSEL_01838\u001b[37m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 404/404 [00:19<00:00, 20.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mLoading data of patient MSEL_01808\u001b[37m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 325/325 [00:16<00:00, 20.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mLoading data of patient MSEL_01838\u001b[37m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 404/404 [00:20<00:00, 19.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mLoading data of patient MSEL_01808\u001b[37m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 325/325 [00:17<00:00, 19.07it/s]\n"
     ]
    }
   ],
   "source": [
    "c.WINDOW_SIZE = c.PREPREDICTION_LENGTH + 1000\n",
    "\n",
    "tabSegments = []\n",
    "for pStr in c.trainPatients:\n",
    "    tabSegments = tabSegments + p.patient(pStr).getLabeledSegments()\n",
    "\n",
    "\n",
    "x_train,y_train = myLib.processDF(tabSegments)\n",
    "x_validation,y_validation = myLib.processDF(p.patient(c.validationPatient).getLabeledSegments())\n",
    "x_test,y_test = myLib.processDF(p.patient(c.testPatient).getLabeledSegments())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e612e98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.31760122 -0.39565403 -1.03526466 ... -0.39547062 -1.02448492\n",
      " -1.33243008]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8bf731e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: 2142\t validation: 397\t test:331\n",
      "\n",
      "TRAIN:     Negatives: 2008 Positives: 134\n",
      "VALIDATION Negatives: 386 Positves: 11\n",
      "TEST       Negatives: 322 Positves: 9\n",
      "\n",
      "6 % of positives\n"
     ]
    }
   ],
   "source": [
    "print(f\"train data: {len(x_train)}\\t validation: {len(x_validation)}\\t test:{len(x_test)}\\n\")\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "print(f\"TRAIN:     Negatives: {counts[0]} Positives: {counts[1]}\")\n",
    "pos = counts[1]\n",
    "neg = counts[0]\n",
    "ratio = round(100 / len(x_train) * pos)\n",
    "unique, counts = np.unique(y_validation, return_counts=True)\n",
    "print(f\"VALIDATION Negatives: {counts[0]} Positves: {counts[1]}\")\n",
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "print(f\"TEST       Negatives: {counts[0]} Positves: {counts[1]}\")\n",
    "\n",
    "\n",
    "print(f\"\\n{ratio} % of positives\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cd55c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getModel1():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(128,activation=tf.nn.relu))\n",
    "    model.add(tf.keras.layers.Dense(2,activation=tf.nn.softmax))\n",
    "\n",
    "    #model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "    model.compile(\n",
    "          optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "          loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "          metrics=[\n",
    "              tf.keras.metrics.BinaryAccuracy(name='accuracy')\n",
    "          ]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "METRICS = [\n",
    "      tf.keras.metrics.TruePositives(name='tp'),\n",
    "      tf.keras.metrics.FalsePositives(name='fp'),\n",
    "      tf.keras.metrics.TrueNegatives(name='tn'),\n",
    "      tf.keras.metrics.FalseNegatives(name='fn'), \n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),\n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "      tf.keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "\n",
    "def getModel2(metrics=METRICS, output_bias=None):\n",
    "  if output_bias is not None:\n",
    "    output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "  model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(\n",
    "          16, activation='relu',\n",
    "          input_shape=(x_train.shape[-1],)),\n",
    "      tf.keras.layers.Dropout(0.5),\n",
    "      tf.keras.layers.Dense(1, activation='sigmoid',\n",
    "                         bias_initializer=output_bias),\n",
    "  ])\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "      loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "      metrics=metrics)\n",
    "\n",
    "  return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e61fbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16)                82000     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 82,017\n",
      "Trainable params: 82,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_prc', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)\n",
    "\n",
    "initial_bias = np.log([pos/neg])\n",
    "\n",
    "model = getModel2(output_bias=initial_bias)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "941ab7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intial Loss: 0.2964 expected : 0.2339\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "results = model.evaluate(x_train, y_train, batch_size=BATCH_SIZE, verbose=0)\n",
    "p0 = pos/(pos+neg)\n",
    "expectedInitLoss = -p0 * math.log(p0) - (1 - p0) * math.log(1-p0)\n",
    "print(f\"Intial Loss: {round(results[0],4)} expected : {round(expectedInitLoss,4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d6e5905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "initial_weights = os.path.join(tempfile.mkdtemp(),\"initial_weights\")\n",
    "model.save_weights(initial_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00cd4fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = getModel2()\n",
    "model.load_weights(initial_weights)\n",
    "model.layers[-1].bias.assign([0.0])\n",
    "zero_bias_history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=20,\n",
    "    validation_data=(x_validation, y_validation), \n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f7eec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = getModel2()\n",
    "model.load_weights(initial_weights)\n",
    "careful_bias_history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=20,\n",
    "    validation_data=(x_validation, y_validation), \n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f47273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_loss(history, label, color = \"C1\"):\n",
    "    # Use a log scale on y-axis to show the wide range of values.\n",
    "    plt.semilogy(history.epoch, history.history['loss'],\n",
    "               color=color, label='Train ' + label)\n",
    "    plt.semilogy(history.epoch, history.history['val_loss'],\n",
    "               color=color, label='Val ' + label,\n",
    "               linestyle=\"--\")\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "\n",
    "plot_loss(zero_bias_history, \"Zero Bias\",\"C0\")\n",
    "plot_loss(careful_bias_history, \"Careful Bias\",\"C2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adaf3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = getModel2()\n",
    "model.load_weights(initial_weights)\n",
    "baseline_history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=20,\n",
    "    validation_data=(x_validation, y_validation), \n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5d2d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history):\n",
    "  metrics = ['loss', 'prc', 'precision', 'recall']\n",
    "  for n, metric in enumerate(metrics):\n",
    "    name = metric.replace(\"_\",\" \").capitalize()\n",
    "    plt.subplot(2,2,n+1)\n",
    "    plt.plot(history.epoch, history.history[metric], color=\"C1\", label='Train')\n",
    "    plt.plot(history.epoch, history.history['val_'+metric],\n",
    "             color=\"C0\", linestyle=\"--\", label='Val')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel(name)\n",
    "    if metric == 'loss':\n",
    "      plt.ylim([0, plt.ylim()[1]])\n",
    "    elif metric == 'auc':\n",
    "      plt.ylim([0.8,1])\n",
    "    else:\n",
    "      plt.ylim([0,1])\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "plot_metrics(baseline_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d78c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = model.evaluate(x_test,y_test)\n",
    "print(f\"\\nloss: {val_loss}\")\n",
    "\n",
    "predictions = model.predict(x_test)\n",
    "res = [np.argmax(x) for x in predictions]\n",
    "for i in range(len(y_test)):\n",
    "    print(f\"{y_test[i]} => {res[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
